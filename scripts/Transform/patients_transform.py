from config import create_spark_session
from pyspark.sql.functions import trim, col
from time_normalization import normalize_time

def transform_patients():
    # Táº¡o Spark Session
    spark = create_spark_session()


    print("ğŸš€ patients table processing...")
    # Table Schema
    print("ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ Printing bronze patients schema...")

    spark.sql("""DESCRIBE TABLE bronze.patients""").show()

    # Load table lÃªn Spark DataFrame
    df_patients = spark.table("bronze.patients")

    df_patients.printSchema()

    # Remove duplicate records
    df_patients = df_patients.drop_duplicates()

    # Xá»­ lÃ½ NULL
    df_patients = df_patients.dropna(subset=['subject_id', 'gender', 'anchor_age', 'anchor_year'])

    # Normalization time
    df_patients = df_patients.withColumn('dod', normalize_time('dod'))

    # Loáº¡i bá» 1 sá»‘ case bá»‹ thá»«a khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i chuá»—i
    string_cols = ["gender", "anchor_year_group"]

    for column_name in string_cols:
        df_patients = df_patients.withColumn(column_name, trim(col(column_name)))

    df_patients.printSchema()

    df_patients.write \
            .format("iceberg") \
            .mode("overwrite") \
            .saveAsTable("silver.patients")

    # spark.table("silver.patients").show(100)
    print("ğŸ“ŠIn bronze")
    spark.sql("SELECT * FROM bronze.patients LIMIT 100").show()
    print("ğŸ“ŠIn silver")
    spark.sql("SELECT * FROM silver.patients LIMIT 100").show() # Táº¡i sao sau khi xá»­ lÃ½ thÃ¬ thá»© tá»± cá»§a báº£ng trong silver láº¡i khÃ¡c trong bronze nhá»‰?
    print("ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ Printing silver patients schema...")
    spark.sql("DESCRIBE TABLE silver.patients").show(truncate=False)
    # Shutdown Spark Session
    spark.stop()


def main():
    transform_patients()

if __name__ == "__main__":
    main()