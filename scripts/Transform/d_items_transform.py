from config import create_spark_session
from pyspark.sql.functions import trim, col

def transform_d_items():
    # T·∫°o Spark Session
    spark = create_spark_session()


    print("üöÄ d_items table processing...")
    # Table schema
    spark.sql("""DESCRIBE TABLE bronze.d_items""").show()

    # b·ªï sung 1 s·ªë ch·ªâ s·ªë c·∫ßn thi·∫øt ƒëang b·ªã thi·∫øu
    spark.sql("""
        UPDATE bronze.d_items
        SET lownormalvalue = 60,
            highnormalvalue = 100
        WHERE itemid = 220045 -- b·ªï sung kho·∫£ng gi√° tr·ªã b√¨nh th∆∞·ªùng cho heart rate 
    """
    )

    spark.sql("""
        UPDATE bronze.d_items
        SET lownormalvalue = 70,
            highnormalvalue = 100
        WHERE itemid = 220052 -- b·ªï sung kho·∫£ng gi√° tr·ªã b√¨nh th∆∞·ªùng cho heart rate 
    """
    )

    spark.sql("""
        UPDATE bronze.d_items
        SET lownormalvalue = 90,
            highnormalvalue = 100
        WHERE itemid = 220277 -- b·ªï sung kho·∫£ng gi√° tr·ªã b√¨nh th∆∞·ªùng cho heart rate 
    """
    )

    # Load table l√™n Spark DataFrame
    df_d_items = spark.table("bronze.d_items")

    # Remove duplicate records
    df_d_items = df_d_items.drop_duplicates()

    # X·ª≠ l√Ω NULL
    df_d_items = df_d_items.dropna(subset=['itemid', 'label', 'linksto', 'category'])
    df_d_items = df_d_items.fillna({'abbreviation': 'N/A', 'unitname': 'N/A', 'param_type': 'N/A', 'lownormalvalue': -1, 'highnormalvalue': -1})

    # Lo·∫°i b·ªè 1 s·ªë case b·ªã th·ª´a kho·∫£ng tr·∫Øng ƒë·∫ßu/cu·ªëi chu·ªói
    string_cols = ["label", "abbreviation", "linksto", "category", "unitname", "param_type"]

    for column_name in string_cols:
        df_d_items = df_d_items.withColumn(column_name, trim(col(column_name)))

    df_d_items.write \
            .format("iceberg") \
<<<<<<< HEAD
            .mode("overwrite") \
=======
            .mode("append") \
>>>>>>> 6586a69ee0b67430d94871a3046d9fa38d12ce86
            .saveAsTable("silver.d_items")
    
    spark.table("silver.d_items").show()

    # Shutdown Spark Session
    spark.stop()


def main():
    transform_d_items()

if __name__ == "__main__":
    main()