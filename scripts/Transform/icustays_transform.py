from config import create_spark_session
from time_normalization import normalize_time
from pyspark.sql.functions import trim, col

def transform_icustays():
    # Táº¡o Spark Session
    spark = create_spark_session()


    print("ğŸš€ icustays table processing...")
    # Table schema
    spark.sql("""DESCRIBE TABLE bronze.icustays""").show()

    # Load table lÃªn Spark DataFrame
    df_icustays = spark.table("bronze.icustays")

    df_icustays.printSchema()
    # Remove duplicate records
    df_icustays = df_icustays.drop_duplicates()

    # Time normalization
    print("ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ Printing bronze icustays schema...")
    spark.sql("DESCRIBE TABLE bronze.icustays").show(truncate=False)

    df_icustays = df_icustays.withColumn('intime', normalize_time('intime'))
    df_icustays = df_icustays.withColumn('outtime', normalize_time('outtime'))

    # Xá»­ lÃ½ NULL
    df_icustays = df_icustays.dropna(subset=['stay_id', 'subject_id', 'hadm_id'])
    df_icustays = df_icustays.fillna({'first_careunit': 'ICU', 'last_careunit': 'ICU'})

    # Loáº¡i bá» 1 sá»‘ case bá»‹ thá»«a khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i chuá»—i
    string_cols = ["first_careunit", "last_careunit"]

    for column_name in string_cols:
        df_icustays = df_icustays.withColumn(column_name, trim(col(column_name)))

    df_icustays.write \
            .format("iceberg") \
            .mode("overwrite") \
            .saveAsTable("silver.icustays")
    
    spark.table("silver.icustays").show()
    print("ğŸ“ŠIn bronze")
    spark.sql("SELECT * FROM bronze.icustays LIMIT 100").show()
    print("ğŸ“ŠIn silver")
    spark.sql("SELECT * FROM silver.icustays LIMIT 100").show()

    print("ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ Printing silver icustays schema...")
    spark.sql("DESCRIBE TABLE bronze.icustays").show(truncate=False)
    # Shutdown Spark Session
    spark.stop()


def main():
    transform_icustays()

if __name__ == "__main__":
    main()